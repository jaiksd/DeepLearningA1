# -*- coding: utf-8 -*-
"""Assignment 1 with Question1 Label.ipynb

Automatically generated by Colaboratory.

Original file is located at
    

Question 1 (2 Marks)

Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use from keras.datasets import fashion_mnist for getting the fashion mnist dataset
"""

#Importing all the libraries that will be used
from os import XATTR_SIZE_MAX
from keras.datasets import fashion_mnist
from keras.datasets import mnist
import numpy as np
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn import metrics
import random
import matplotlib.pyplot as plt
import wandb
import argparse


# wandb.login(key='fbf80504ccef17f5f3b05723be7ea4caff805164')


# #An independent function which calculated accuracy given the true and predicted class labels
def accuracy(y_true, y_pred):
  """
  calculating the accuracy
  """
  acc = np.sum(np.equal(y_true,y_pred))/y_true.shape[0]
  return acc

"""
Class for implementing the feedforward neural network's forward propagation functionality.
"""
class FeedForwardNN():
  def __init__(self, hidden_layer_sizes, optimizer, activation_function, output_activation, loss_function, epochs = 1, batch_size = 4, initialization = "Random", log=0, console_log = 1, train_losses_list = None, train_accuracy_list = None, val_losses_list = None, val_accuracy_list = None):
    """


    - log: Log onto WandB (default 0).
    - console_log: Log onto console (default 1).
    -self: Reference to the object itself.
    - hidden_layer_sizes: List indicating the sizes of hidden layers (number of hidden layers for the network).
    """
    self.hidden_layer_sizes = hidden_layer_sizes
    self.optimizer = optimizer
    self.input_layer_size=0
    self.output_layer_size=1
    self.epochs = epochs
    #- batch_size: Batch size (default 1024).
    self.batch_size = batch_size
    self.loss_function = loss_function
    self.dw = {}
    self.db = {}
    self.activation_function = activation_function
    self.output_activation = output_activation


    #- initialization: Weight initialization method (default "Random").
    self.initialization = initialization
    #Layer sizes array will be initialzed after input and output layer size is obtained
    self.weights = {}
    self.biases = {}
    self.val_losses_list = val_losses_list
    self.val_accuracy_list = val_accuracy_list
    self.log = log
    self.console_log = console_log
    self.layer_sizes = []

    self.dA = {}
    self.dH = {}
    self.A = {}
    self.H = {}


    self.train_losses_list = train_losses_list
    self.train_accuracy_list = train_accuracy_list



  def initialize_weights(self):
    """
    initilizing the weights
    """
    np.random.seed(137)
    np.random.RandomState(137)
    self.layer_sizes = [self.input_layer_size] + self.hidden_layer_sizes + [self.output_layer_size]
    weight_counts = len(self.hidden_layer_sizes)
    weight_counts+=1

    self.optimizer.initialize(self.layer_sizes)
    #defining a utility function
    def utility_x():
      return 1;
    i=0
    while i<(weight_counts):

      if self.initialization == "Xavier":
        # using the xavier method to iniliatize the weights
        limit = np.sqrt(2 / float(self.layer_sizes[i] + self.layer_sizes[i+1]))
        self.weights[i+1] = np.random.normal(0.0, limit, size=(self.layer_sizes[i], self.layer_sizes[i+1]))


      if self.initialization == "random":

        self.weights[i+1] = np.random.randn(self.layer_sizes[i], self.layer_sizes[i+1])


      #setting the biases
      self.biases[i+1] = np.zeros((1, self.layer_sizes[i+1]))
      i+=1



  def forward_prop(self, X):
    """
    performing forward propagation on the data X
    """
    self.H = {}
    self.A = {}

    i=0
    #initializing i for while loop
    self.H[0] = X.reshape(1,-1)


    while i<(len(self.hidden_layer_sizes)):
      mat=np.matmul(self.H[i], self.weights[i+1])
      fin=mat+self.biases[i+1]
      self.A[i+1] =  fin
      self.H[i+1] = self.activation_function.calculate_activation(self.A[i+1])
      i+=1

    #perform a(x) and h(a(x)) = softmax(a(x))
    temp=np.matmul(self.H[len(self.hidden_layer_sizes)], self.weights[len(self.hidden_layer_sizes)+1])
    ad=temp + self.biases[len(self.hidden_layer_sizes)+1]
    self.A[len(self.hidden_layer_sizes)+1] =  ad
    self.H[len(self.hidden_layer_sizes)+1] = self.output_activation.calculate_activation(self.A[len(self.hidden_layer_sizes)+1])
    return

  def back_prop(self, X, Y,  dw_i, db_i):
    """
    performing backward propogation .
    """
    #calculate the gradient of loss wrt the activation of output layer
    self.dA[len(self.hidden_layer_sizes)+1] = self.loss_function.last_output_derivative(self.H[len(self.hidden_layer_sizes)+1], Y, self.output_activation.calculate_derivative(self.A[len(self.hidden_layer_sizes)+1]))

    #using the formula taught in the class,that is applying chain rule here
    for i in range(len(self.hidden_layer_sizes), -1, -1):
      dw_i[i+1] = np.matmul(self.H[i].T, self.dA[i+1])

      db_i[i+1] = self.dA[i+1]
      if i!=0:

        self.dH[i] = np.matmul(self.dA[i+1],self.weights[i+1].T)

        self.dA[i] = np.multiply(self.activation_function.calculate_derivative(self.A[i]), self.dH[i])

    return dw_i, db_i


  def fit(self, X, Y, X_val, Y_val):
    """
    func to fit the data (X,Y) on the model. This performs forward + backward pass for epoch number of times. Gradient is updated after each batch is processed.
    """
    # columns in output (label count)
    self.output_layer_size = Y.shape[1]
    self.input_layer_size = X.shape[1]*X.shape[1] # Number of features in data(features)

    self.initialize_weights()
    for e in range(self.epochs):
      y_preds = []

      count = -1
      for i in range(len(self.hidden_layer_sizes)+1):
        self.dw[i+1] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))
        self.db[i+1] = np.zeros((1, self.layer_sizes[i+1]))

      for x, y in zip(X, Y):
        dw_i = {}
        db_i = {}
        count += 1

        if count==self.batch_size:
          #Done wih current batch
          count = 0
          #checking it the optimizer is nag
          if self.optimizer.optimizer_name()=="nag":
            w_look_ahead = {}
            b_look_ahead = {}
            for i in range(len(self.hidden_layer_sizes)+1):
              sub_w= self.optimizer.beta*self.optimizer.update_history_w[i+1]
              w_look_ahead[i+1] = self.weights[i+1] - sub_w
              sub_b=self.optimizer.beta*self.optimizer.update_history_b[i+1]
              b_look_ahead[i+1] = self.biases[i+1] -sub_b

            #updating the biases
            biases_old = self.biases
            #updating the weights
            weights_old = self.weights

            self.weights = w_look_ahead
            self.biases = b_look_ahead
            self.forward_prop(x)
            dw_look_ahead, db_look_ahead = self.back_prop(x,y, dw_i, db_i)
            self.weights, self.biases = self.optimizer.update_parameters(weights_old, biases_old, dw_look_ahead, db_look_ahead, self.hidden_layer_sizes)

          else:
            self.weights, self.biases = self.optimizer.update_parameters(self.weights, self.biases, self.dw, self.db, self.hidden_layer_sizes)
          for i in range(len(self.hidden_layer_sizes)+1):
            self.dw[i+1] = np.zeros((self.layer_sizes[i], self.layer_sizes[i+1]))
            self.db[i+1] = np.zeros((1, self.layer_sizes[i+1]))


        #Forward Propogation
        self.forward_prop(x)



        #Predictions
        y_preds.append(self.H[len(self.hidden_layer_sizes)+1])

        #Backward Propogation using Loss funtion
        self.back_prop(x,y, dw_i, db_i)

        #defining a function for calculating the derivative(NT)
        def derivative_of_x(x):
          exponentials = np.exp(x)
          return exponentials / np.sum(exponentials)

        for i in range(len(self.hidden_layer_sizes)+1):
          self.dw[i+1] += dw_i[i+1]
          self.db[i+1] += db_i[i+1]

      #Update weights based on loss(GD hence once every epoch update)
      if self.optimizer.optimizer_name()=="nag":
        w_look_ahead = {}
        b_look_ahead = {}
        for i in range(len(self.hidden_layer_sizes)+1):
          w_look_ahead[i+1] = self.weights[i+1] - self.optimizer.beta*self.optimizer.update_history_w[i+1]
          b_look_ahead[i+1] = self.biases[i+1] - self.optimizer.beta*self.optimizer.update_history_b[i+1]

        weights_old = self.weights
        biases_old = self.biases
        self.weights = w_look_ahead
        self.biases = b_look_ahead
        self.forward_prop(x)
        dw_look_ahead, db_look_ahead = self.back_prop(x,y, dw_i, db_i)
        self.weights, self.biases = self.optimizer.update_parameters(weights_old, biases_old, dw_look_ahead, db_look_ahead, self.hidden_layer_sizes)

      else:
        self.weights, self.biases = self.optimizer.update_parameters(self.weights, self.biases, self.dw, self.db, self.hidden_layer_sizes)
      y_preds = np.array(y_preds).squeeze()
      y_preds_validation = self.predict(X_val)
      #getting all the losses and updation
      training_loss = self.loss_function.calculate_loss(Y, y_preds, self.batch_size)
      validation_loss = self.loss_function.calculate_loss(Y_val, y_preds_validation, self.batch_size)
      #getting accuracy
      training_accuracy = accuracy(np.argmax(Y,1), np.argmax(y_preds,1))
      validation_accuracy = accuracy(np.argmax(Y_val,1), np.argmax(y_preds_validation,1))
      if self.log==1:
        #Log metrics to wandb
        wandb.log({"Training_accuracy": training_accuracy, "Validation_accuracy": validation_accuracy, "Training_loss": training_loss, "Validation_loss": validation_loss, 'Epoch': e+1})
      if self.console_log == 1:
        #Log results to console
        print("Epoch: ",e+1," Training Loss: ",training_loss, " Validation Loss:",validation_loss ," Training Accuracy: ",training_accuracy, " Validation Accuracy:", validation_accuracy)
      if self.val_accuracy_list != None:
        self.val_accuracy_list.append(validation_accuracy)
      if self.val_losses_list != None:
        self.val_losses_list.append(validation_loss)
      if self.train_accuracy_list != None:
        self.train_accuracy_list.append(training_accuracy)
      if self.train_losses_list != None:
        self.train_losses_list.append(training_loss)

    return training_loss, validation_loss, training_accuracy, validation_accuracy

  def predict(self, X):

    out_prob = []
    #function to predict and storing the result in the out_prob
    for x in X:
      values = self.forward_prop(x)
      predictions = self.H[len(self.hidden_layer_sizes)+1]
      out_prob.append(predictions)

    out_prob = np.array(out_prob).squeeze()
    return out_prob

class StocasticGD():
  """
  This class implements the Stochastic Gradient Descent (SGD) optimizer.

  Parameters:

    learning_rate: The rate at which the optimizer updates the weights during training.
    weight_decay: The factor by which the optimizer reduces the weights to combat overfitting.
    """
  def __init__(self, learning_rate = 0.001, weight_decay = 0.0):
    self.learning_rate = learning_rate
    self.weight_decay = weight_decay

  def set_learning_rate(self, learning_rate):
    self.learning_rate = learning_rate
  def set_uts():
    a=np.ones(5)
    return a

  def set_initial_parameters(self, parameters):
    self.learning_rate = parameters["learning_rate"]
    self.weight_decay = parameters["weight_decay"]

  def set_weight_decay(self, weight_decay):
    self.weight_decay = weight_decay


  def optimizer_name(self):
    return "gd"

  def initialize(self, all_layers):
    return


  #this function updates all the parameters
  #like weights,biases,dw,db,layers
  def update_parameters(self, weights, biases, dw, db, layers):

    i=0
    #formula I used below is same as what we taught in class that is upadating weights and biases for every datapoints
    while i<(len(layers)+1):
        dw[i+1] = dw[i+1] + self.weight_decay*weights[i+1]


        weights[i+1] = weights[i+1] - self.learning_rate * dw[i+1]

        biases[i+1] = biases[i+1] - self.learning_rate * db[i+1]
        i+=1
    return weights, biases


class MomentumGD():
  """
  This class defines the Momentum Gradient Descent optimizer.

  Parameters:

    learning_rate: The rate at which the optimizer adjusts the weights during training.
    weight_decay: The factor by which the optimizer reduces the weights to prevent overfitting.
    beta: The momentum parameter for the optimizer.
  """
  def __init__(self, learning_rate = 0.001, beta = 0.001, weight_decay = 0.0):
    self.learning_rate = learning_rate
    self.update_history_w = {}
    self.update_history_b = {}
    self.beta = beta
    self.initialized = False
    self.weight_decay = weight_decay


  def optimizer_name(self):
    return "momentum"


  def set_weight_decay(self, weight_decay):
    self.weight_decay = weight_decay

  def initialize(self, all_layers):
    self.update_history_w.clear()
    self.update_history_b.clear()
    i=0
    while i<(len(all_layers)-1):
      self.update_history_w[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.update_history_b[i+1] = np.zeros((1, all_layers[i+1]))
      i+=1




  def set_learning_rate(self, learning_rate):
    self.learning_rate = learning_rate

  def set_initial_parameters(self, parameters):
    self.learning_rate = parameters["learning_rate"]
    self.beta = parameters["beta"]
    self.weight_decay = parameters["weight_decay"]


  def update_parameters(self, weights, biases, dw, db, layers):
    """
    updating the parameters
    """
    i=0
    while i<(len(layers)+1):
        dw[i+1] = dw[i+1] + self.weight_decay*weights[i+1]

        self.update_history_w[i+1] =self.beta*self.update_history_w[i+1] + self.learning_rate*dw[i+1]
        weights[i+1] = weights[i+1] - self.update_history_w[i+1]

        self.update_history_b[i+1] =self.beta*self.update_history_b[i+1] + self.learning_rate*db[i+1]
        biases[i+1] = biases[i+1] - self.update_history_b[i+1]
        i+=1
    return weights, biases


class NAG():
  """
  This class is for implementing the Nesterov accelerated Gradient Descent optimizer.

  Parameters:

    learning_rate: The rate at which the optimizer adjusts the weights during training.
    beta: The momentum parameter for the optimizer.
    """
  def __init__(self, learning_rate = 0.001, beta = 0.9):
    self.w_look_ahead={}
    self.beta = beta
    #setting the look_ahead symbol
    self.b_look_ahead={}

    self.db_look_ahead={}
    #setting the learning rate
    self.learning_rate = learning_rate

    self.initialized = False
    self.update_history_w = {}
    self.dw_look_ahead={}
    self.update_history_b = {}

  def optimizer_name(self):
    return "nag"



  def initialize(self, all_layers):
    self.w_look_ahead.clear()
    self.update_history_b.clear()
    #clearing all the parameters
    self.b_look_ahead.clear()
    self.update_history_w.clear()
    self.db_look_ahead.clear()
    self.dw_look_ahead.clear()


    for i in range(len(all_layers)-1):
      self.update_history_w[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.update_history_b[i+1] = np.zeros((1, all_layers[i+1]))
      self.dw_look_ahead[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.db_look_ahead[i+1] = np.zeros((1, all_layers[i+1]))
      self.w_look_ahead[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.b_look_ahead[i+1] = np.zeros((1, all_layers[i+1]))



  def set_initial_parameters(self, parameters):
    self.learning_rate = parameters["learning_rate"]
    self.beta = parameters["beta"]

  def set_learning_rate(self, learning_rate):
    self.learning_rate = learning_rate



  def update_parameters(self, weights, biases, dw, db, layers):
    """
    updating the parameters
    """
    i=0
    while i<(len(layers)+1):
        self.update_history_w[i+1] = self.beta*self.update_history_w[i+1] + self.learning_rate*dw[i+1]
        self.update_history_b[i+1] = self.beta*self.update_history_b[i+1] + self.learning_rate*db[i+1]
        weights[i+1] = weights[i+1] - self.update_history_w[i+1]
        biases[i+1] = biases[i+1] - self.update_history_b[i+1]
        i+=1

    return weights, biases


class RMSProp():
  """
  This class implements the RMSProp optimizer.

  Parameters:

    learning_rate: The rate at which the optimizer adjusts the weights during training.
    weight_decay: Weight decay parameter for regularization.
    beta: The momentum parameter for the optimizer.
    epsilon: A small value added to the denominator to prevent division by zero.
    """


  def __init__(self, learning_rate = 0.001, beta = 0.001, epsilon = 1e-8, weight_decay = 0.0):
    self.learning_rate = learning_rate
    #_init_ function initializes all the parameters
    self.v_w = {}
    self.v_b = {}
    self.epsilon = epsilon
    self.beta = beta


    self.initialized = False
    self.weight_decay = weight_decay

  def initialize(self, all_layers):
    self.v_b.clear()
    self.v_w.clear()

    i=0
    while i<(len(all_layers)-1):
      self.v_w[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.v_b[i+1] = np.zeros((1, all_layers[i+1]))
      i+=1

  def set_weight_decay(self, weight_decay):
    self.weight_decay = weight_decay

  def optimizer_name(self):
    return "rmsprop"

  def set_learning_rate(self, learning_rate):
    self.learning_rate = learning_rate



  def set_initial_parameters(self, parameters):
    self.learning_rate = parameters["learning_rate"]
    self.beta = parameters["beta"]
    self.epsilon = parameters["epsilon"]
    self.weight_decay = parameters["weight_decay"]


  def update_parameters(self, weights, biases, dw, db, layers):
    """
    updating the parameters
    """
    i=0
    while i<(len(layers)+1):
      #iteratively updating the weights and biases
        dw[i+1] = dw[i+1] + self.weight_decay*weights[i+1]
        self.v_w[i+1] =self.beta*self.v_w[i+1] + (1-self.beta)* ((dw[i+1])**2)
        self.v_b[i+1] =self.beta*self.v_b[i+1] + (1-self.beta)* ((db[i+1])**2)

        weights[i+1] = weights[i+1] - ((self.learning_rate)/np.sqrt(self.v_w[i+1] + self.epsilon))*dw[i+1]
        biases[i+1] = biases[i+1] - ((self.learning_rate)/np.sqrt(self.v_b[i+1] + self.epsilon))*db[i+1]
        i+=1
    return weights, biases


class Adam():
  """
  This class defines the Adam optimizer.

  Parameters:

    learning_rate: The rate at which the optimizer adjusts the weights during training.
    weight_decay: Weight decay parameter for regularization.
    beta1: The exponential decay rate for the first moment estimates.
    beta2: The exponential decay rate for the second moment estimates.
    epsilon: A small value added to the denominator to prevent division by zero.
    """
  def __init__(self, learning_rate = 0.001,beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, weight_decay = 0.0):
    self.learning_rate = learning_rate
    self.beta1 = beta1
    self.beta2 = beta2
    self.v_w = {}
    self.v_b = {}
    self.epsilon = epsilon
    self.initialized = False
    self.iterations = 1
    self.weight_decay = weight_decay

    self.m_w = {}
    self.m_b = {}


  def initialize(self, all_layers):
    self.v_w.clear()
    self.v_b.clear()
    self.m_w.clear()
    self.m_b.clear()
    i=0
    while i<(len(all_layers)-1):
      self.v_w[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.v_b[i+1] = np.zeros((1, all_layers[i+1]))
      self.m_w[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.m_b[i+1] = np.zeros((1, all_layers[i+1]))
      i+=1

  def set_learning_rate(self, learning_rate):
    self.learning_rate = learning_rate

  def optimizer_name(self):
    return "adam"

  def set_weight_decay(self, weight_decay):
    self.weight_decay = weight_decay



  def set_initial_parameters(self, parameters):
    self.learning_rate = parameters["learning_rate"]
    self.beta1 = parameters["beta1"]
    self.beta2 = parameters["beta2"]
    self.epsilon = parameters["epsilon"]
    self.weight_decay = parameters["weight_decay"]


  def update_parameters(self, weights, biases, dw, db, layers):
    """
    updating the parameters
    """
    i=0
    while i<(len(layers)+1):

        dw[i+1] = dw[i+1] + self.weight_decay*weights[i+1]

        self.m_w[i+1] = self.beta1*self.m_w[i+1] + (1-self.beta1)* (dw[i+1])
        self.m_b[i+1] = self.beta1*self.m_b[i+1] + (1-self.beta1)* (db[i+1])
        self.v_w[i+1] = self.beta2*self.v_w[i+1] + (1-self.beta2)* ((dw[i+1])**2)
        self.v_b[i+1] = self.beta2*self.v_b[i+1] + (1-self.beta2)* ((db[i+1])**2)

        #this is the formula taught in the class
        m_w_hat = self.m_w[i+1]/(1-(self.beta1**self.iterations))
        m_b_hat = self.m_b[i+1]/(1-(self.beta1**self.iterations))
        v_w_hat = self.v_w[i+1]/(1-(self.beta2**self.iterations))
        v_b_hat = self.v_b[i+1]/(1-(self.beta2**self.iterations))

        #updating the weights
        weights[i+1] = weights[i+1] - ((self.learning_rate)/(np.sqrt(v_w_hat) + self.epsilon))*(m_w_hat)
        biases[i+1] = biases[i+1] - ((self.learning_rate)/(np.sqrt(v_b_hat) + self.epsilon))*(m_b_hat)
        i+=1
    #moving to next iteration
    self.iterations += 1

    return weights, biases


class Nadam():

  """
  Defines the NAdam optimizer.

  Parameters:

    learning_rate: Rate at which the optimizer updates the weights during training.
    weight_decay: Weight decay parameter for regularization.
    beta1: Exponential decay rate for the first moment estimates.
    beta2: Exponential decay rate for the second moment estimates.
    epsilon: Small value added to the denominator to prevent division by zero.
    """
  def __init__(self, learning_rate = 0.001, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, weight_decay = 0.0):
    self.learning_rate = learning_rate
    self.beta1 = beta1
    self.beta2 = beta2
    self.v_w = {}
    self.v_b = {}
    self.epsilon = epsilon
    self.initialized = False

    self.m_w = {}
    self.m_b = {}
    self.iterations = 1
    self.weight_decay = weight_decay

  def initialize(self, all_layers):
    self.v_w.clear()
    self.v_b.clear()
    self.m_w.clear()
    self.m_b.clear()
    i=0
    while i<(len(all_layers)-1):
      self.v_w[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.v_b[i+1] = np.zeros((1, all_layers[i+1]))
      self.m_w[i+1] = np.zeros((all_layers[i], all_layers[i+1]))
      self.m_b[i+1] = np.zeros((1, all_layers[i+1]))
      i+=1

  def set_learning_rate(self, learning_rate):
    self.learning_rate = learning_rate

  def set_weight_decay(self, weight_decay):
    self.weight_decay = weight_decay

  def optimizer_name(self):
    return "nadam"

  def set_initial_parameters(self, parameters):
    self.learning_rate = parameters["learning_rate"]
    self.beta1 = parameters["beta1"]
    self.beta2 = parameters["beta2"]
    self.epsilon = parameters["epsilon"]
    self.weight_decay = parameters["weight_decay"]


  def update_parameters(self, weights, biases, dw, db, layers):
    """
    updating the parameters
    """
    i=0
    while i<(len(layers)+1):

        #this is the gradient
        dw[i+1] = dw[i+1] + self.weight_decay*weights[i+1]

        self.m_w[i+1] = self.beta1*self.m_w[i+1] + (1-self.beta1)* (dw[i+1])
        self.m_b[i+1] = self.beta1*self.m_b[i+1] + (1-self.beta1)* (db[i+1])

        self.v_w[i+1] = self.beta2*self.v_w[i+1] + (1-self.beta2)* ((dw[i+1])**2)
        self.v_b[i+1] = self.beta2*self.v_b[i+1] + (1-self.beta2)* ((db[i+1])**2)

        #calculating the m_w_hat and m_b_hat
        m_w_hat = self.m_w[i+1]/(1-(self.beta1**self.iterations))
        m_b_hat = self.m_b[i+1]/(1-(self.beta1**self.iterations))

         #calculating the v_w_hat and v_b_hat
        v_w_hat = self.v_w[i+1]/(1-(self.beta2**self.iterations))
        v_b_hat = self.v_b[i+1]/(1-(self.beta2**self.iterations))

        #updating the weights and biases
        weights[i+1] = weights[i+1] - ((self.learning_rate)/(np.sqrt(v_w_hat) + self.epsilon))*(self.beta1 * m_w_hat + ((1-self.beta1)/(1-(self.beta1**self.iterations))*dw[i+1]))
        biases[i+1] = biases[i+1] - ((self.learning_rate)/(np.sqrt(v_b_hat) + self.epsilon))*(self.beta1 * m_b_hat + ((1-self.beta1)/(1-(self.beta1**self.iterations))*db[i+1]))
        i+=1

    self.iterations += 1

    return weights, biases

class Softmax():
  """
  Class of Softmax activation function.
  """
  def calculate_derivative(self, X):
    softmax = self.calculate_activation(X)
    return softmax*(1-softmax)

  def calculate_activation(self, X):
    #Utility to calculate softmax function
    X_max = np.max(X)
    exponentials = np.exp(X - X_max)
    return exponentials / np.sum(exponentials)


class Sigmoid():
  """
  Implementing Sigmoid activation function.
  """
  def calculate_derivative(self, X):
    val = self.calculate_activation(X)
    return val*(1-val)

  def calculate_activation(self, X):
    return 1.0/(1.0+np.exp(-X))


class Tanh():
  """
  implementing Tanh activation function.
  """
  def calculate_derivative(self,X):
    s=1 - (np.tanh(X) ** 2)
    return s

  def calculate_activation(self,X):
    s=np.tanh(X)
    return s


class Identity():
    def calculate_activation(self, X):
        return X

    def calculate_derivative(self, X):
        # Derivative of the identity function is always 1
        return np.ones_like(X)

class ReLU():
  """
  Class to implement ReLU activation function.
  """
  def calculate_derivative(self,X):
    X[X <= 0.0] = 0.0
    X[X > 0.0] = 1.0
    return X
  def calculate_activation(self,X):
    return X * (X > 0)

class CrossEntropy():
  """
  cross entropy loss function

  """
  #this function returns the name cross_entropy_loss
  def name(self):
    return "cross_entropy_loss"

  def calculate_loss(self, Y_true, Y_pred, batch_size):
    #this function calculates the loss
    for p in Y_pred[0]:
      if np.isnan(p) or p<10e-8:
        p=10e-8
    loss=np.multiply(Y_pred,Y_true)
    loss=loss[loss!=0]
    loss=-np.log(loss)
    loss=np.mean(loss)

    return loss

  def calculate_derivative(self, Y_pred,Y_true):
    return -Y_true/(Y_pred)

  def last_output_derivative(self, Y_pred,Y_true,activation_derivative):
    for p in Y_pred[0]:
      if np.isnan(p) or p<10e-8:
        p=10e-8
    return -(Y_true - Y_pred)




class SquaredErrorLoss():
  """
  squared loss function
  """

  def name(self):
    #this function returns the name of the loss
    return "squared_loss"

  def calculate_derivative(self, Y_pred,Y_true):
    return (Y_pred)*(Y_pred-Y_true)/len(Y_true)
  def calculate_loss(self, Y_true, Y_pred, batch_size):
    return (1/2) * np.sum((Y_pred-Y_true)**2)/len(Y_true)



  def last_output_derivative(self, Y_pred,Y_true, activation_derivative):
    for p in Y_pred[0]:
      if np.isnan(p) or p<10e-8:
        p=10e-8
    return (Y_pred - Y_true)*activation_derivative/len(Y_true)

#Add layer sizes for the hidden layers
layers = [32, 32, 32]

optimizers = {"gradient_descent":StocasticGD(), "momentum_gd":MomentumGD(), "nag":NAG(), "rmsprop":RMSProp(), "adam":Adam(), "nadam":Nadam()}
loss_functions = {"cross_entropy":CrossEntropy(), "squared_loss":SquaredErrorLoss()}
activation_functions = {"sigmoid": Sigmoid(), "softmax":Softmax(), "tanh": Tanh(), "ReLU":ReLU()}


#Select optimizer(momentum)
optimizer_momentum = optimizers["momentum_gd"]
optimizer_parameters_momentum = {"learning_rate":0.0001, "beta":0.6, "weight_decay":0}
#optimizer_parameters_momentum = {"learning_rate":0.01, "beta":0.9}

optimizer_momentum.set_initial_parameters(optimizer_parameters_momentum)

#Select optimizer(nag)
optimizer_nag = optimizers["nag"]
optimizer_parameters_nag = {"learning_rate":0.001, "beta":0.9}
optimizer_nag.set_initial_parameters(optimizer_parameters_nag)

#Select optimizer(sgd)
optimizer_sgd = optimizers["gradient_descent"]
optimizer_parameters_sgd = {"learning_rate":0.001, "weight_decay":0.5}
optimizer_sgd.set_initial_parameters(optimizer_parameters_sgd)

#Select optimizer(rmsprop)
optimizer_rmsprop = optimizers["rmsprop"]
optimizer_parameters_rmsprop = {"learning_rate":0.01, "beta":0.9, "epsilon":1e-8, "weight_decay":0.5}
optimizer_rmsprop.set_initial_parameters(optimizer_parameters_rmsprop)


#Select optimizer(nadam)
optimizer_nadam = optimizers["nadam"]
optimizer_parameters_nadam = {"learning_rate":0.0001, "beta1":0.09, "beta2":0.999, "epsilon":1e-8, "weight_decay":0}
optimizer_nadam.set_initial_parameters(optimizer_parameters_nadam)




#Select optimizer(adam)
optimizer_adam = optimizers["adam"]
optimizer_parameters_adam = {"learning_rate":0.0001, "beta1":0.09, "beta2":0.999, "epsilon":1e-8, "weight_decay":0.5}
optimizer_adam.set_initial_parameters(optimizer_parameters_adam)


#Select loss function
loss_cross_entropy = loss_functions["cross_entropy"]
loss_squared = loss_functions["squared_loss"]

#Select activation(hidden layers)
activation_sigmoid = activation_functions["sigmoid"]
activation_softmax = activation_functions["softmax"]
activation_tanh = activation_functions["tanh"]
activation_ReLU = activation_functions["ReLU"]
activation_iden=Identity()

#Select activation(output layer)
output_activation_softmax = activation_functions["softmax"]

# model = FeedForwardNN(layers, optimizer_adam, activation_ReLU, output_activation_softmax, loss_squared, 5, 512, initialization = "Xavier")
# model.fit(X_train, Y_train, X_val, Y_val)

# #Accuracy for test data
# y_preds = model.predict(X_test)
# print(accuracy(np.argmax(Y_test,1), np.argmax(y_preds,1)))

"""Question 4 (10 Marks)

Use the sweep functionality provided by wandb to find the best values for the hyperparameters listed below. Use the standard train/test split of fashion_mnist (use (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()). Keep 10% of the training data aside as validation data for this hyperparameter search. Here are some suggestions for different values to try for hyperparameters. As you can quickly see that this leads to an exponential number of combinations. You will have to think about strategies to do this hyperparameter search efficiently. Check out the options provided by wandb.sweep and write down what strategy you chose and why.

    number of epochs: 5, 10
    number of hidden layers: 3, 4, 5
    size of every hidden layer: 32, 64, 128
    weight decay (L2 regularisation): 0, 0.0005, 0.5
    learning rate: 1e-3, 1 e-4
    optimizer: sgd, momentum, nesterov, rmsprop, adam, nadam
    batch size: 16, 32, 64
    weight initialisation: random, Xavier
    activation functions: sigmoid, tanh, ReLU

wandb will automatically generate the following plots. Paste these plots below using the "Add Panel to Report" feature. Make sure you use meaningful names for each sweep (e.g. hl_3_bs_16_ac_tanh to indicate that there were 3 hidden layers, batch size was 16 and activation function was ReLU) instead of using the default names (whole-sweep, kind-sweep) given by wandb.
"""


def train(args, X_train, X_val, X_test, Y_train, Y_val, Y_test):
      output = []
      hidden_size = args.hidden_size
      num_layers = args.num_layers
      
      for _ in range(num_layers):
          output.append(hidden_size)


      batch_size = args.batch_size
      initialization = args.weight_init
      optimizers = {"gradient_descent":StocasticGD(), "momentum_gd":MomentumGD(), "nag":NAG(), "rmsprop":RMSProp(), "adam":Adam(), "nadam":Nadam()}
      loss_functions = {"cross_entropy":CrossEntropy(), "mean_squared_error":SquaredErrorLoss()}
      activation_functions = {"sigmoid": Sigmoid(), "softmax":Softmax(), "tanh": Tanh(), "ReLU":ReLU(),"identity":Identity()}
      learning_rate = args.learning_rate
      weight_decay = args.weight_decay
      beta = args.beta
      beta1=args.beta1
      beta2=args.beta2
      momentum=args.momentum
      epochs = args.epochs


      if args.loss=="cross_entropy":
        loss_cross_entropy=CrossEntropy()
      else:
        loss_cross_entropy=SquaredErrorLoss()


      if args.activation=="sigmoid":
        activation = activation_functions["sigmoid"]

      if args.activation=="tanh":
        activation = activation_functions["tanh"]

      if args.activation=="ReLU":
        activation = activation_functions["ReLU"]
      if args.activation=="identity":
        activation = activation_functions["identity"]

      output_activation = activation_functions["softmax"]

      if args.optimizer=="sgd":
        #optimizer selected is sgd
        optimizer = optimizers["gradient_descent"]
        optimizer_parameters_sgd = {"learning_rate":learning_rate, "weight_decay":weight_decay}
        optimizer.set_initial_parameters(optimizer_parameters_sgd)

      if args.optimizer=="momentum":
        #optimizer selected is momentum
        optimizer = optimizers["momentum_gd"]
        optimizer_parameters_momentum = {"learning_rate":learning_rate, "beta":momentum, "weight_decay":weight_decay}
        optimizer.set_initial_parameters(optimizer_parameters_momentum)

      if args.optimizer=="nag":
        #optimizer selected is nag
        optimizer = optimizers["nag"]
        optimizer_parameters_nag = {"learning_rate":learning_rate, "beta":momentum}
        optimizer.set_initial_parameters(optimizer_parameters_nag)

      if args.optimizer=="rmsprop":
        #optimizer selected is rmsprop
        optimizer = optimizers["rmsprop"]
        optimizer_parameters_rmsprop = {"learning_rate":learning_rate, "beta":beta, "epsilon":1e-8, "weight_decay": weight_decay}
        optimizer.set_initial_parameters(optimizer_parameters_rmsprop)

      if args.optimizer=="adam":
        #optimizer selected is adam
        optimizer = optimizers["adam"]
        optimizer_parameters_adam = {"learning_rate":learning_rate, "beta1":beta1, "beta2":beta2, "epsilon":1e-8, "weight_decay": weight_decay}
        optimizer.set_initial_parameters(optimizer_parameters_adam)

      if args.optimizer=="nadam":
        #optimizer selected is nadam
        optimizer = optimizers["nadam"]
        optimizer_parameters_nadam = {"learning_rate":learning_rate, "beta1":beta1, "beta2":beta2, "epsilon":1e-8, "weight_decay": weight_decay}
        optimizer.set_initial_parameters(optimizer_parameters_nadam)


      #Training the model
      #Ensure that log=1 parameter is set for logging onto wandb
      model = FeedForwardNN(output, optimizer, activation, output_activation, loss_cross_entropy, epochs, batch_size, initialization , log=1, console_log = 1)

      train_loss, val_loss, train_accuracy, val_accuracy = model.fit(X_train, Y_train, X_val, Y_val)
      wandb.log({"accuracy": val_accuracy})


parser = argparse.ArgumentParser()

parser.add_argument('-wp' , '--wandb_project', help='Project name used to track experiments in Weights & Biases dashboard' , type=str, default='DL_Assignment_1')
parser.add_argument('-we', '--wandb_entity' , help='Wandb Entity used to track experiments in the Weights & Biases dashboard.' , type=str, default='cs23m030')
parser.add_argument('-d', '--dataset', help='choices: ["mnist", "fashion_mnist"]', choices = ["mnist", "fashion_mnist"],type=str, default='fashion_mnist')
parser.add_argument('-e', '--epochs', help="Number of epochs to train neural network.", type=int, default=10)
parser.add_argument('-b', '--batch_size', help="Batch size used to train neural network.", type=int, default=64)
parser.add_argument('-l','--loss', help = 'choices: ["mean_squared_error", "cross_entropy"]' , choices = ["mean_squared_error", "cross_entropy"],type=str, default='cross_entropy')
parser.add_argument('-o', '--optimizer', help = 'choices: ["sgd", "momentum", "nag", "rmsprop", "adam", "nadam"]', choices = ["sgd", "momentum", "nag", "rmsprop", "adam", "nadam"],type=str, default = 'adam')
parser.add_argument('-lr', '--learning_rate', help = 'Learning rate used to optimize model parameters', type=float, default=0.0005)
parser.add_argument('-m', '--momentum', help='Momentum used by momentum and nag optimizers.',type=float, default=0.9)
parser.add_argument('-beta', '--beta', help='Beta used by rmsprop optimizer',type=float, default=0.9)
parser.add_argument('-beta1', '--beta1', help='Beta1 used by adam and nadam optimizers.',type=float, default=0.9)
parser.add_argument('-beta2', '--beta2', help='Beta2 used by adam and nadam optimizers.',type=float, default=0.999)
parser.add_argument('-eps', '--epsilon', help='Epsilon used by optimizers.',type=float, default=1e-8)
parser.add_argument('-w_d', '--weight_decay', help='Weight decay used by optimizers.',type=float, default=0.0005)
parser.add_argument('-w_i', '--weight_init', help = 'choices: ["random", "Xavier"]', choices = ["random", "Xavier"],type=str, default='random')
parser.add_argument('-nhl', '--num_layers', help='Number of hidden layers used in feedforward neural network.',type=int, default=4)
parser.add_argument('-sz', '--hidden_size', help ='Number of hidden neurons in a feedforward layer.', type=int, default=128)
parser.add_argument('-a', '--activation', help='choices: ["identity", "sigmoid", "tanh", "ReLU"]', choices = ["identity", "sigmoid", "tanh", "ReLU"],type=str, default='ReLU')
# parser.add_argument('-wl', '--wandb_log', help="To log training metrics on wandb.", type=int, default=1)
# parser.add_argument('-cm', '--confusion_matrix', help="Plot Confusion Matrix on wandb.", type=int, default=0)

arguments = parser.parse_args()


#data preprocessing and dataset selection
def load_dataset(name):

  if name == 'fashion_mnist':
    (X_train_com, Y_train_com), (X_test, Y_test) = fashion_mnist.load_data()
  else:
    (X_train_com, Y_train_com), (X_test, Y_test) = mnist.load_data()
  
  #Normalizing the data
  X_train_com = X_train_com/255.0
  X_test = X_test/255.0
  np.random.seed(137)
  encoder = OneHotEncoder()

  #Splitting to get 10% data as validation set
  X_train, X_val, Y_train, Y_val = train_test_split(X_train_com, Y_train_com, test_size=0.1, random_state=137)
  Y_train_unencoded = Y_train
  #One hot encoding of the class labels
  Y_val = encoder.fit_transform(np.expand_dims(Y_val,1)).toarray()
  Y_train = encoder.fit_transform(np.expand_dims(Y_train,1)).toarray()
  Y_test = encoder.fit_transform(np.expand_dims(Y_test,1)).toarray()
  
  return X_train, X_val, X_test, Y_train, Y_val, Y_test

X_train, X_val, X_test, Y_train, Y_val, Y_test = load_dataset(arguments.dataset)


# Create Run
wandb.init(project = arguments.wandb_project, name = arguments.wandb_entity)
# TRAIN MODEL via parsing arguments
model = train(arguments, X_train, X_val, X_test, Y_train, Y_val, Y_test)

# Finish run
wandb.finish()

